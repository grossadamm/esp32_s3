services:
  mcp-voice-agent:
    build: .
    ports:
      - "3000:3000"  # Voice Agent (main entry point)
    environment:
      - NODE_ENV=production
      - LLM_PROVIDER=openai
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - NVIDIA_VISIBLE_DEVICES=all
      - CUDA_VISIBLE_DEVICES=all
    volumes:
      - ./data:/data
      - ./logs:/app/logs
      - ./uploads:/app/voice-agent/uploads
    restart: unless-stopped
    # GPU support for NVIDIA hardware
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    # Alternative GPU access (comment out deploy section above if using this)
    # runtime: nvidia
    # devices:
    #   - /dev/nvidia0:/dev/nvidia0
    #   - /dev/nvidiactl:/dev/nvidiactl
    #   - /dev/nvidia-uvm:/dev/nvidia-uvm
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  dev-tools-api:
    build: .
    environment:
      - NODE_ENV=production
    volumes:
      - ./data:/data
      - ./logs:/app/logs
    command: ["node", "mcp-servers/dev-tools-mcp/dist/http-server.js"]
    restart: unless-stopped
    depends_on:
      - mcp-voice-agent

  finance-api:
    build: .
    environment:
      - NODE_ENV=production
      - PORT=3000
    volumes:
      - ./data:/data
      - ./logs:/app/logs
    command: ["node", "mcp-servers/finance-mcp/dist/http-server.js"]
    restart: unless-stopped
    depends_on:
      - mcp-voice-agent

volumes:
  logs:
  uploads: 