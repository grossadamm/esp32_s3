<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Realtime Audio Test Client</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
        }
        .status {
            padding: 10px;
            border-radius: 5px;
            margin: 10px 0;
        }
        .connected { background-color: #d4edda; color: #155724; }
        .disconnected { background-color: #f8d7da; color: #721c24; }
        .recording { background-color: #fff3cd; color: #856404; }
        .audio-ready { background-color: #cce5ff; color: #004085; }
        .vad-ready { background-color: #e7f3ff; color: #004085; }
        .speaking { background-color: #d1ecf1; color: #0c5460; }
        button {
            padding: 10px 20px;
            margin: 5px;
            border: none;
            border-radius: 5px;
            cursor: pointer;
        }
        .start { background-color: #28a745; color: white; }
        .stop { background-color: #dc3545; color: white; }
        .transcript {
            background-color: #f8f9fa;
            border: 1px solid #dee2e6;
            border-radius: 5px;
            padding: 15px;
            margin: 10px 0;
            min-height: 100px;
            white-space: pre-wrap;
        }
        .log {
            background-color: #f1f3f4;
            border-radius: 5px;
            padding: 10px;
            margin: 10px 0;
            max-height: 300px;
            overflow-y: auto;
            font-family: monospace;
            font-size: 12px;
        }
    </style>
    <!-- VAD Library (ricky0123/vad-web) -->
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web@1.14.0/dist/ort.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@ricky0123/vad-web@0.0.22/dist/bundle.min.js"></script>
</head>
<body>
    <h1>üéôÔ∏è Realtime Audio Test Client</h1>
    
    <div id="status" class="status disconnected">
        Disconnected
    </div>
    
    <div>
        <button id="connectBtn" class="start" onclick="connect()">Connect</button>
        <button id="disconnectBtn" class="stop" onclick="disconnect()" disabled>Disconnect</button>
        <button id="recordBtn" class="start" onclick="startRecording()" disabled>Start Recording</button>
        <button id="stopBtn" class="stop" onclick="stopRecording()" disabled>Stop Recording</button>
    </div>
    
    <h3>Live Transcript:</h3>
    <div id="transcript" class="transcript"></div>
    
    <h3>Connection Log:</h3>
    <div id="log" class="log"></div>

    <script>
        let ws = null;
        let mediaRecorder = null;
        let audioContext = null;
        let silentAudio = null;
        let audioContextReady = false;
        let audioQueue = [];
        let vad = null;
        let vadReady = false;
        let isSpeaking = false;
        
        // üéØ AUDIO CONTEXT KEEPALIVE MANAGER
        class AudioContextKeepAlive {
            constructor() {
                this.audioContext = null;
                this.silentAudio = null;
                this.isActivated = false;
                this.monitorInterval = null;
            }
            
            async initializeOnUserGesture() {
                if (this.isActivated) return;
                
                try {
                    log('üéß Initializing AudioContext keepalive...');
                    
                    // 1. Create AudioContext
                    this.audioContext = new AudioContext();
                    
                    // 2. Resume if suspended (browser policy compliance)
                    if (this.audioContext.state === 'suspended') {
                        await this.audioContext.resume();
                        log('‚ñ∂Ô∏è AudioContext resumed');
                    }
                    
                    // 3. Create silent audio keepalive (cleaner approach)
                    this.createSilentAudioKeepalive();
                    
                    // 4. Set up periodic monitoring
                    this.startMonitoring();
                    
                    this.isActivated = true;
                    audioContextReady = true;
                    
                    log('‚úÖ AudioContext keepalive activated!');
                    updateStatus('Audio System Ready', 'audio-ready');
                    
                } catch (error) {
                    log(`‚ùå AudioContext init failed: ${error.message}`);
                }
            }
            
            createSilentAudioKeepalive() {
                // Create a silent audio source using AudioContext
                const sampleRate = this.audioContext.sampleRate;
                const buffer = this.audioContext.createBuffer(1, 1, sampleRate);
                
                // Create silent buffer source
                const silentSource = this.audioContext.createBufferSource();
                silentSource.buffer = buffer;
                silentSource.loop = true;
                
                // Create gain node set to almost silent
                const gainNode = this.audioContext.createGain();
                gainNode.gain.value = 0.001; // Very quiet
                
                // Connect nodes
                silentSource.connect(gainNode);
                gainNode.connect(this.audioContext.destination);
                
                // Start the silent audio
                silentSource.start();
                
                log('üîá Silent audio keepalive started');
            }
            
            startMonitoring() {
                this.monitorInterval = setInterval(() => {
                    if (this.audioContext && this.audioContext.state === 'suspended') {
                        log('‚ö†Ô∏è AudioContext suspended, attempting resume...');
                        this.audioContext.resume().then(() => {
                            log('‚úÖ AudioContext resumed automatically');
                        }).catch(err => {
                            log(`‚ùå Failed to resume: ${err.message}`);
                        });
                    }
                }, 2000); // Check every 2 seconds
            }
            
            cleanup() {
                if (this.monitorInterval) {
                    clearInterval(this.monitorInterval);
                }
                if (this.silentAudio) {
                    this.silentAudio.pause();
                }
            }
        }
        
        // üé§ VAD MANAGER
        async function initializeVAD() {
            try {
                log('üß† Loading VAD model...');
                
                // Wait for library to load
                let attempts = 0;
                while (!window.vad && attempts < 10) {
                    log(`Waiting for VAD library... attempt ${attempts + 1}`);
                    await new Promise(resolve => setTimeout(resolve, 500));
                    attempts++;
                }
                
                if (!window.vad || !window.vad.MicVAD) {
                    throw new Error('VAD library not found');
                }
                
                // Create VAD instance using official API
                vad = await window.vad.MicVAD.new({
                    onSpeechStart: () => {
                        log('üó£Ô∏è VAD: Speech start detected');
                        isSpeaking = true;
                        updateStatus('Speaking...', 'speaking');
                    },
                    onSpeechEnd: (audio) => {
                        log(`ü§´ VAD: Speech end detected, audio length: ${audio.length}`);
                        isSpeaking = false;
                        updateStatus('Connected', 'connected');
                        
                        // Send the detected speech audio to the server
                        if (ws && ws.readyState === WebSocket.OPEN) {
                            sendAudioToServer(audio);
                        }
                    },
                    onVADMisfire: () => {
                        log('‚ö†Ô∏è VAD: Misfire detected');
                    }
                });
                
                vadReady = true;
                log('‚úÖ MicVAD loaded and ready');
                updateStatus('VAD Ready', 'vad-ready');
                return true;
            } catch (error) {
                log(`‚ùå VAD initialization failed: ${error.message}`);
                return false;
            }
        }

        // Helper function to send audio data to server (with stack overflow fix)
        function sendAudioToServer(audioFloat32Array) {
            try {
                // Convert Float32Array to PCM16 for OpenAI compatibility
                const pcmData = new Int16Array(audioFloat32Array.length);
                for (let i = 0; i < audioFloat32Array.length; i++) {
                    pcmData[i] = Math.max(-32768, Math.min(32767, audioFloat32Array[i] * 32767));
                }
                
                // Convert to base64 efficiently (avoid stack overflow with large arrays)
                const uint8Array = new Uint8Array(pcmData.buffer);
                let base64Audio = '';
                
                // Process in chunks to avoid "Maximum call stack size exceeded"
                const chunkSize = 8192; // Process 8KB at a time
                for (let i = 0; i < uint8Array.length; i += chunkSize) {
                    const chunk = uint8Array.slice(i, i + chunkSize);
                    base64Audio += btoa(String.fromCharCode.apply(null, chunk));
                }
                
                // Send to server
                ws.send(JSON.stringify({
                    type: 'audio_chunk',
                    audio: base64Audio
                }));
                
                log(`üì§ Sent VAD audio chunk: ${pcmData.length} samples`);
            } catch (error) {
                log(`‚ùå Error sending audio to server: ${error.message}`);
            }
        }
        
        // Initialize the keepalive manager
        const audioKeepAlive = new AudioContextKeepAlive();
        
        function log(message) {
            const logDiv = document.getElementById('log');
            const timestamp = new Date().toLocaleTimeString();
            logDiv.innerHTML += `[${timestamp}] ${message}\n`;
            logDiv.scrollTop = logDiv.scrollHeight;
        }
        
        function updateStatus(text, className) {
            const statusDiv = document.getElementById('status');
            statusDiv.textContent = text;
            statusDiv.className = `status ${className}`;
        }
        
        async function connect() {
            try {
                // üéØ ACTIVATE AUDIO CONTEXT KEEPALIVE ON USER GESTURE
                await audioKeepAlive.initializeOnUserGesture();
                
                // üß† INITIALIZE VAD
                await initializeVAD();
                
                // Dynamic WebSocket URL construction (same as mobile UI)
                const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
                const wsUrl = `${protocol}//${window.location.host}/api/audio/realtime`;
                
                // Debug WebSocket URL construction
                console.log('üîç WebSocket URL Debug:', {
                    'window.location.protocol': window.location.protocol,
                    'window.location.host': window.location.host,
                    'protocol': protocol,
                    'wsUrl': wsUrl
                });
                log(`üîó Connecting to: ${wsUrl}`);
                
                ws = new WebSocket(wsUrl);
                
                ws.onopen = () => {
                    log('‚úÖ Connected to WebSocket');
                    updateStatus('Connected', 'connected');
                    document.getElementById('connectBtn').disabled = true;
                    document.getElementById('disconnectBtn').disabled = false;
                    document.getElementById('recordBtn').disabled = false;
                };
                
                ws.onmessage = (event) => {
                    try {
                        const data = JSON.parse(event.data);
                        log(`üì® Received: ${data.type}`);
                        
                        switch (data.type) {
                            case 'session_ready':
                                log('üéØ Session ready');
                                break;
                            case 'audio_delta':
                                // Play audio chunk (base64 encoded)
                                playAudioChunk(data.audio);
                                break;
                            case 'transcript_delta':
                                // Update live transcript
                                updateTranscript(data.text);
                                break;
                            case 'speech_started':
                                log('üé§ Speech detected');
                                updateStatus('Listening...', 'recording');
                                break;
                            case 'speech_stopped':
                                log('üîá Speech ended');
                                updateStatus('Connected', 'connected');
                                break;
                            case 'error':
                                log(`‚ùå Error: ${JSON.stringify(data.error)}`);
                                break;
                        }
                    } catch (e) {
                        log(`‚ùå Failed to parse message: ${e.message}`);
                    }
                };
                
                ws.onclose = () => {
                    log('üîå WebSocket closed');
                    updateStatus('Disconnected', 'disconnected');
                    resetButtons();
                };
                
                ws.onerror = (error) => {
                    log(`‚ùå WebSocket error: ${error}`);
                    updateStatus('Error', 'disconnected');
                    resetButtons();
                };
                
            } catch (error) {
                log(`‚ùå Connection failed: ${error.message}`);
            }
        }
        
        function disconnect() {
            if (ws) {
                ws.close();
            }
            if (mediaRecorder && mediaRecorder.state === 'recording') {
                stopRecording();
            }
            audioKeepAlive.cleanup();
        }
        
        function resetButtons() {
            document.getElementById('connectBtn').disabled = false;
            document.getElementById('disconnectBtn').disabled = true;
            document.getElementById('recordBtn').disabled = true;
            document.getElementById('stopBtn').disabled = true;
        }
        
        async function startRecording() {
            try {
                if (vadReady && vad) {
                    log('üé§ Starting VAD-powered recording');
                    
                    // Use the official VAD API - it handles microphone access automatically
                    await vad.start();
                    
                    log('‚úÖ VAD recording started - waiting for speech detection');
                    updateStatus('Listening...', 'recording');
                    document.getElementById('recordBtn').disabled = true;
                    document.getElementById('stopBtn').disabled = false;
                    
                } else {
                    log('‚ö†Ô∏è VAD not available, cannot start recording');
                    updateStatus('VAD Not Ready', 'disconnected');
                }
                
            } catch (error) {
                log(`‚ùå Recording failed: ${error.message}`);
            }
        }
        
        function stopRecording() {
            // Stop VAD if it's running
            if (vadReady && vad && typeof vad.pause === 'function') {
                try {
                    vad.pause();
                    log('üõë VAD recording stopped');
                } catch (error) {
                    log(`‚ùå Error stopping VAD: ${error.message}`);
                }
            }
            
            // Reset VAD state
            isSpeaking = false;
            
            log('üõë Recording stopped');
            updateStatus('Connected', 'connected');
            document.getElementById('recordBtn').disabled = false;
            document.getElementById('stopBtn').disabled = true;
        }
        
        function updateTranscript(text) {
            const transcriptDiv = document.getElementById('transcript');
            transcriptDiv.textContent += text;
            transcriptDiv.scrollTop = transcriptDiv.scrollHeight;
        }
        
        // üì± Mobile-friendly audio playback with PCM16 to WAV conversion
        function pcm16ToWav(pcmData, sampleRate) {
            const length = pcmData.length;
            const arrayBuffer = new ArrayBuffer(44 + length * 2);
            const view = new DataView(arrayBuffer);
            
            // WAV header
            const writeString = (offset, string) => {
                for (let i = 0; i < string.length; i++) {
                    view.setUint8(offset + i, string.charCodeAt(i));
                }
            };
            
            writeString(0, 'RIFF');
            view.setUint32(4, 36 + length * 2, true);
            writeString(8, 'WAVE');
            writeString(12, 'fmt ');
            view.setUint32(16, 16, true);
            view.setUint16(20, 1, true);
            view.setUint16(22, 1, true);
            view.setUint32(24, sampleRate, true);
            view.setUint32(28, sampleRate * 2, true);
            view.setUint16(32, 2, true);
            view.setUint16(34, 16, true);
            writeString(36, 'data');
            view.setUint32(40, length * 2, true);
            
            // PCM data
            for (let i = 0; i < length; i++) {
                view.setInt16(44 + i * 2, pcmData[i], true);
            }
            
            return arrayBuffer;
        }

        function playAudioChunk(base64Audio) {
            const isMobile = /iPhone|iPad|iPod|Android/i.test(navigator.userAgent);
            
            try {
                // Decode base64 to PCM16 data from OpenAI
                const binaryString = atob(base64Audio);
                const arrayBuffer = new ArrayBuffer(binaryString.length);
                const uint8Array = new Uint8Array(arrayBuffer);
                
                for (let i = 0; i < binaryString.length; i++) {
                    uint8Array[i] = binaryString.charCodeAt(i);
                }

                const pcmData = new Int16Array(arrayBuffer);
                const sampleRate = 24000;
                const duration = pcmData.length / sampleRate;
                
                log(`üîä Audio chunk: ${pcmData.length} samples, ${duration.toFixed(3)}s`);
                
                if (isMobile) {
                    // üì± Mobile: Convert PCM16 to WAV and use Audio element
                    log('üì± Using mobile-friendly audio playback');
                    const wavBuffer = pcm16ToWav(pcmData, sampleRate);
                    const blob = new Blob([wavBuffer], { type: 'audio/wav' });
                    const audioUrl = URL.createObjectURL(blob);
                    
                    const audio = new Audio(audioUrl);
                    audio.play().then(() => {
                        log('üì± Playing mobile audio chunk');
                    }).catch(error => {
                        log(`üì± Mobile audio play failed: ${error.message}`);
                    });
                    
                    audio.onended = () => {
                        URL.revokeObjectURL(audioUrl); // Clean up memory
                    };
                    
                    audio.onerror = () => {
                        log('üì± Mobile audio error');
                        URL.revokeObjectURL(audioUrl);
                    };
                    
                } else {
                    // üñ•Ô∏è Desktop: Use Web Audio API
                    if (!audioContextReady || !audioKeepAlive.audioContext) {
                        log('‚ö†Ô∏è AudioContext not ready, skipping desktop audio');
                        return;
                    }
                    
                    try {
                        const audioBuffer = audioKeepAlive.audioContext.createBuffer(1, pcmData.length, sampleRate);
                        const channelData = audioBuffer.getChannelData(0);
                        
                        // Convert Int16 PCM to Float32 audio data
                        for (let i = 0; i < pcmData.length; i++) {
                            channelData[i] = pcmData[i] / 32768.0;
                        }
                        
                        const source = audioKeepAlive.audioContext.createBufferSource();
                        source.buffer = audioBuffer;
                        source.connect(audioKeepAlive.audioContext.destination);
                        source.start();
                        log(`üñ•Ô∏è Playing Web Audio chunk (${duration.toFixed(2)}s)`);
                        
                    } catch (webAudioError) {
                        log(`‚ö†Ô∏è Web Audio failed, using fallback: ${webAudioError.message}`);
                        // Fallback to mobile approach even on desktop
                        const wavBuffer = pcm16ToWav(pcmData, sampleRate);
                        const blob = new Blob([wavBuffer], { type: 'audio/wav' });
                        const audioUrl = URL.createObjectURL(blob);
                        const audio = new Audio(audioUrl);
                        audio.play().catch(err => log(`‚ùå Fallback audio failed: ${err.message}`));
                        audio.onended = () => URL.revokeObjectURL(audioUrl);
                    }
                }
                
            } catch (error) {
                log(`‚ùå Audio playback error: ${error.message}`);
            }
        }
        
        // Auto-connect on page load for testing
        window.onload = () => {
            log('üöÄ Page loaded, ready to connect');
            log('üí° Click "Connect" to activate audio system and load VAD');
        };
    </script>
</body>
</html>