<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Realtime Audio Test Client</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
        }
        .status {
            padding: 10px;
            border-radius: 5px;
            margin: 10px 0;
        }
        .connected { background-color: #d4edda; color: #155724; }
        .disconnected { background-color: #f8d7da; color: #721c24; }
        .recording { background-color: #fff3cd; color: #856404; }
        .audio-ready { background-color: #cce5ff; color: #004085; }
        .vad-ready { background-color: #e7f3ff; color: #004085; }
        .speaking { background-color: #d1ecf1; color: #0c5460; }
        button {
            padding: 10px 20px;
            margin: 5px;
            border: none;
            border-radius: 5px;
            cursor: pointer;
        }
        .start { background-color: #28a745; color: white; }
        .stop { background-color: #dc3545; color: white; }
        .transcript {
            background-color: #f8f9fa;
            border: 1px solid #dee2e6;
            border-radius: 5px;
            padding: 15px;
            margin: 10px 0;
            min-height: 100px;
            white-space: pre-wrap;
        }
        .log {
            background-color: #f1f3f4;
            border-radius: 5px;
            padding: 10px;
            margin: 10px 0;
            max-height: 300px;
            overflow-y: auto;
            font-family: monospace;
            font-size: 12px;
        }
    </style>
    <!-- VAD Library (ricky0123/vad-web) -->
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web@1.14.0/dist/ort.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@ricky0123/vad-web@0.0.22/dist/bundle.min.js"></script>
</head>
<body>
    <h1>üéôÔ∏è Realtime Audio Test Client</h1>
    
    <div id="status" class="status disconnected">
        Disconnected
    </div>
    
    <div>
        <button id="connectBtn" class="start" onclick="connect()">Connect</button>
        <button id="disconnectBtn" class="stop" onclick="disconnect()" disabled>Disconnect</button>
        <button id="recordBtn" class="start" onclick="startRecording()" disabled>Start Recording</button>
        <button id="stopBtn" class="stop" onclick="stopRecording()" disabled>Stop Recording</button>
    </div>
    
    <h3>Live Transcript:</h3>
    <div id="transcript" class="transcript"></div>
    
    <h3>Connection Log:</h3>
    <div id="log" class="log"></div>

    <script>
        let ws = null;
        let mediaRecorder = null;
        let audioContext = null;
        let silentAudio = null;
        let audioContextReady = false;
        let audioQueue = [];
        let vad = null;
        let vadReady = false;
        let isSpeaking = false;
        
        // üéØ AUDIO CONTEXT KEEPALIVE MANAGER
        class AudioContextKeepAlive {
            constructor() {
                this.audioContext = null;
                this.silentAudio = null;
                this.isActivated = false;
                this.monitorInterval = null;
            }
            
            async initializeOnUserGesture() {
                if (this.isActivated) return;
                
                try {
                    log('üéß Initializing AudioContext keepalive...');
                    
                    // 1. Create AudioContext
                    this.audioContext = new AudioContext();
                    
                    // 2. Resume if suspended (browser policy compliance)
                    if (this.audioContext.state === 'suspended') {
                        await this.audioContext.resume();
                        log('‚ñ∂Ô∏è AudioContext resumed');
                    }
                    
                    // 3. Create silent audio keepalive (cleaner approach)
                    this.createSilentAudioKeepalive();
                    
                    // 4. Set up periodic monitoring
                    this.startMonitoring();
                    
                    this.isActivated = true;
                    audioContextReady = true;
                    
                    log('‚úÖ AudioContext keepalive activated!');
                    updateStatus('Audio System Ready', 'audio-ready');
                    
                } catch (error) {
                    log(`‚ùå AudioContext init failed: ${error.message}`);
                }
            }
            
            createSilentAudioKeepalive() {
                // Create a silent audio source using AudioContext
                const sampleRate = this.audioContext.sampleRate;
                const buffer = this.audioContext.createBuffer(1, 1, sampleRate);
                
                // Create silent buffer source
                const silentSource = this.audioContext.createBufferSource();
                silentSource.buffer = buffer;
                silentSource.loop = true;
                
                // Create gain node set to almost silent
                const gainNode = this.audioContext.createGain();
                gainNode.gain.value = 0.001; // Very quiet
                
                // Connect nodes
                silentSource.connect(gainNode);
                gainNode.connect(this.audioContext.destination);
                
                // Start the silent audio
                silentSource.start();
                
                log('üîá Silent audio keepalive started');
            }
            
            startMonitoring() {
                this.monitorInterval = setInterval(() => {
                    if (this.audioContext && this.audioContext.state === 'suspended') {
                        log('‚ö†Ô∏è AudioContext suspended, attempting resume...');
                        this.audioContext.resume().then(() => {
                            log('‚úÖ AudioContext resumed automatically');
                        }).catch(err => {
                            log(`‚ùå Failed to resume: ${err.message}`);
                        });
                    }
                }, 2000); // Check every 2 seconds
            }
            
            cleanup() {
                if (this.monitorInterval) {
                    clearInterval(this.monitorInterval);
                }
                if (this.silentAudio) {
                    this.silentAudio.pause();
                }
            }
        }
        
        // üé§ VAD MANAGER
        async function initializeVAD() {
            try {
                log('üß† Loading VAD model...');
                
                // Wait for library to load
                let attempts = 0;
                while (!window.vad && attempts < 10) {
                    log(`Waiting for VAD library... attempt ${attempts + 1}`);
                    await new Promise(resolve => setTimeout(resolve, 500));
                    attempts++;
                }
                
                if (!window.vad || !window.vad.MicVAD) {
                    throw new Error('VAD library not found');
                }
                
                // Create VAD instance using official API
                vad = await window.vad.MicVAD.new({
                    onSpeechStart: () => {
                        log('üó£Ô∏è VAD: Speech start detected');
                        isSpeaking = true;
                        updateStatus('Speaking...', 'speaking');
                    },
                    onSpeechEnd: (audio) => {
                        log(`ü§´ VAD: Speech end detected, audio length: ${audio.length}`);
                        isSpeaking = false;
                        updateStatus('Connected', 'connected');
                        
                        // Send the detected speech audio to the server
                        if (ws && ws.readyState === WebSocket.OPEN) {
                            sendAudioToServer(audio);
                        }
                    },
                    onVADMisfire: () => {
                        log('‚ö†Ô∏è VAD: Misfire detected');
                    }
                });
                
                vadReady = true;
                log('‚úÖ MicVAD loaded and ready');
                updateStatus('VAD Ready', 'vad-ready');
                return true;
            } catch (error) {
                log(`‚ùå VAD initialization failed: ${error.message}`);
                return false;
            }
        }

        // Helper function to send audio data to server
        function sendAudioToServer(audioFloat32Array) {
            try {
                // Convert Float32Array to PCM16 for OpenAI compatibility
                const pcmData = new Int16Array(audioFloat32Array.length);
                for (let i = 0; i < audioFloat32Array.length; i++) {
                    pcmData[i] = Math.max(-32768, Math.min(32767, audioFloat32Array[i] * 32767));
                }
                
                // Convert to base64
                const uint8Array = new Uint8Array(pcmData.buffer);
                const base64Audio = btoa(String.fromCharCode.apply(null, uint8Array));
                
                // Send to server
                ws.send(JSON.stringify({
                    type: 'audio_chunk',
                    audio: base64Audio
                }));
                
                log(`üì§ Sent VAD audio chunk: ${pcmData.length} samples`);
            } catch (error) {
                log(`‚ùå Error sending audio to server: ${error.message}`);
            }
        }
        
        // Initialize the keepalive manager
        const audioKeepAlive = new AudioContextKeepAlive();
        
        function log(message) {
            const logDiv = document.getElementById('log');
            const timestamp = new Date().toLocaleTimeString();
            logDiv.innerHTML += `[${timestamp}] ${message}\n`;
            logDiv.scrollTop = logDiv.scrollHeight;
        }
        
        function updateStatus(text, className) {
            const statusDiv = document.getElementById('status');
            statusDiv.textContent = text;
            statusDiv.className = `status ${className}`;
        }
        
        async function connect() {
            try {
                // üéØ ACTIVATE AUDIO CONTEXT KEEPALIVE ON USER GESTURE
                await audioKeepAlive.initializeOnUserGesture();
                
                // üß† INITIALIZE VAD
                await initializeVAD();
                
                // Dynamic WebSocket URL construction (same as mobile UI)
                const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
                const wsUrl = `${protocol}//${window.location.host}/api/audio/realtime`;
                
                // Debug WebSocket URL construction
                console.log('üîç WebSocket URL Debug:', {
                    'window.location.protocol': window.location.protocol,
                    'window.location.host': window.location.host,
                    'protocol': protocol,
                    'wsUrl': wsUrl
                });
                log(`üîó Connecting to: ${wsUrl}`);
                
                ws = new WebSocket(wsUrl);
                
                ws.onopen = () => {
                    log('‚úÖ Connected to WebSocket');
                    updateStatus('Connected', 'connected');
                    document.getElementById('connectBtn').disabled = true;
                    document.getElementById('disconnectBtn').disabled = false;
                    document.getElementById('recordBtn').disabled = false;
                };
                
                ws.onmessage = (event) => {
                    try {
                        const data = JSON.parse(event.data);
                        log(`üì® Received: ${data.type}`);
                        
                        switch (data.type) {
                            case 'session_ready':
                                log('üéØ Session ready');
                                break;
                            case 'audio_delta':
                                // Play audio chunk (base64 encoded)
                                playAudioChunk(data.audio);
                                break;
                            case 'transcript_delta':
                                // Update live transcript
                                updateTranscript(data.text);
                                break;
                            case 'speech_started':
                                log('üé§ Speech detected');
                                updateStatus('Listening...', 'recording');
                                break;
                            case 'speech_stopped':
                                log('üîá Speech ended');
                                updateStatus('Connected', 'connected');
                                break;
                            case 'error':
                                log(`‚ùå Error: ${JSON.stringify(data.error)}`);
                                break;
                        }
                    } catch (e) {
                        log(`‚ùå Failed to parse message: ${e.message}`);
                    }
                };
                
                ws.onclose = () => {
                    log('üîå WebSocket closed');
                    updateStatus('Disconnected', 'disconnected');
                    resetButtons();
                };
                
                ws.onerror = (error) => {
                    log(`‚ùå WebSocket error: ${error}`);
                    updateStatus('Error', 'disconnected');
                    resetButtons();
                };
                
            } catch (error) {
                log(`‚ùå Connection failed: ${error.message}`);
            }
        }
        
        function disconnect() {
            if (ws) {
                ws.close();
            }
            if (mediaRecorder && mediaRecorder.state === 'recording') {
                stopRecording();
            }
            audioKeepAlive.cleanup();
        }
        
        function resetButtons() {
            document.getElementById('connectBtn').disabled = false;
            document.getElementById('disconnectBtn').disabled = true;
            document.getElementById('recordBtn').disabled = true;
            document.getElementById('stopBtn').disabled = true;
        }
        
        async function startRecording() {
            try {
                if (vadReady && vad) {
                    log('üé§ Starting VAD-powered recording');
                    
                    // Use the official VAD API - it handles microphone access automatically
                    await vad.start();
                    
                    log('‚úÖ VAD recording started - waiting for speech detection');
                    updateStatus('Listening...', 'recording');
                    document.getElementById('recordBtn').disabled = true;
                    document.getElementById('stopBtn').disabled = false;
                    
                } else {
                    log('‚ö†Ô∏è VAD not available, cannot start recording');
                    updateStatus('VAD Not Ready', 'disconnected');
                }
                
            } catch (error) {
                log(`‚ùå Recording failed: ${error.message}`);
            }
        }
        
        function stopRecording() {
            // Stop VAD if it's running
            if (vadReady && vad && typeof vad.pause === 'function') {
                try {
                    vad.pause();
                    log('üõë VAD recording stopped');
                } catch (error) {
                    log(`‚ùå Error stopping VAD: ${error.message}`);
                }
            }
            
            // Reset VAD state
            isSpeaking = false;
            
            log('üõë Recording stopped');
            updateStatus('Connected', 'connected');
            document.getElementById('recordBtn').disabled = false;
            document.getElementById('stopBtn').disabled = true;
        }
        
        function updateTranscript(text) {
            const transcriptDiv = document.getElementById('transcript');
            transcriptDiv.textContent += text;
            transcriptDiv.scrollTop = transcriptDiv.scrollHeight;
        }
        
        function playAudioChunk(base64Audio) {
            if (!audioContextReady || !audioKeepAlive.audioContext) {
                log('‚ö†Ô∏è AudioContext not ready, audio playback skipped');
                return;
            }
            
            try {
                // üéØ PROPER AUDIO PLAYBACK USING WEB AUDIO API
                const audioData = atob(base64Audio);
                const arrayBuffer = new ArrayBuffer(audioData.length);
                const view = new Uint8Array(arrayBuffer);
                for (let i = 0; i < audioData.length; i++) {
                    view[i] = audioData.charCodeAt(i);
                }
                
                // Decode audio data and play through AudioContext
                audioKeepAlive.audioContext.decodeAudioData(arrayBuffer.slice()).then(audioBuffer => {
                    const source = audioKeepAlive.audioContext.createBufferSource();
                    source.buffer = audioBuffer;
                    source.connect(audioKeepAlive.audioContext.destination);
                    source.start();
                    log(`üîä Playing audio chunk (${audioBuffer.duration.toFixed(2)}s)`);
                }).catch(error => {
                    // Fallback to regular audio element if decoding fails
                    log(`‚ö†Ô∏è AudioContext decode failed, using fallback: ${error.message}`);
                    const audio = new Audio('data:audio/wav;base64,' + base64Audio);
                    audio.play().catch(err => {
                        log(`‚ùå Fallback audio failed: ${err.message}`);
                    });
                });
                
            } catch (error) {
                log(`‚ùå Audio playback error: ${error.message}`);
            }
        }
        
        // Auto-connect on page load for testing
        window.onload = () => {
            log('üöÄ Page loaded, ready to connect');
            log('üí° Click "Connect" to activate audio system and load VAD');
        };
    </script>
</body>
</html>